{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows simple implementations of a few of the algorithms for reasoning with functional dependencies, for normalization during relational database design. Specifically, it contains code for finding the closure of a set of functional dependencies, finding keys and candidate keys, and decomposing a schema into BCNF.\n",
    "\n",
    "First, we create a class to represent a Functional Dependency, to make the code cleaner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Basic Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from functools import cmp_to_key\n",
    "\n",
    "# A class to encapsulate a Functional Dependency, and some helper functions\n",
    "class FD:\n",
    "        def __init__(self, lhs, rhs):\n",
    "                self.lhs = frozenset(list(lhs))\n",
    "                self.rhs = frozenset(list(rhs))\n",
    "        def __str__(self):\n",
    "                return ''.join(self.lhs) + \" -> \" + ''.join(self.rhs)\n",
    "        def __eq__(self, other):\n",
    "                return (self.lhs == other.lhs) & (self.rhs == other.rhs)\n",
    "        def __hash__(self):\n",
    "                return hash(self.lhs) * hash(self.rhs)\n",
    "        def isTrivial(self):\n",
    "                \"\"\"A functional dependency is trivial if the right hand side is a subset of the left h.s.\"\"\"\n",
    "                return self.lhs >= self.rhs\n",
    "\n",
    "            \n",
    "# implement the old-school cmp in python3 \n",
    "def cmp(a,b):\n",
    "    return (a > b) - (a < b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following is not really needed for normalization, but may be useful to get intuitions about FDs\n",
    "# IMPORTANT: Don't forget that for an FD to hold on a relation schema, it must hold on all legal (possible) instances\n",
    "# It is not sufficient to hold on a few of the instances\n",
    "class Relation:\n",
    "        def __init__(self, schema):\n",
    "                self.tuples = list()\n",
    "                self.schema = schema\n",
    "        def add(self, t):\n",
    "                if len(t) == len(self.schema):\n",
    "                        self.tuples.append(t)\n",
    "                else:\n",
    "                        print (\"Added tuple does not match the length of the schema\")\n",
    "        def checkIfMatch(self, t1, t2, attr_set):\n",
    "                return all(t1[self.schema.index(attr)] == t2[self.schema.index(attr)] for attr in attr_set)\n",
    "        def checkFDHolds(self, fd):\n",
    "                \"\"\"Go over all pairs of tuples and see if the FD is violated\"\"\"\n",
    "                holds = True\n",
    "                for t1 in self.tuples:\n",
    "                        for t2 in self.tuples:\n",
    "                                if t1 < t2 and self.checkIfMatch(t1, t2, fd.lhs) and not self.checkIfMatch(t1, t2, fd.rhs):\n",
    "                                        print (\"Tuples \" + str(t1) + \" and \" + str(t2) + \" violate the FD \" + str(fd))\n",
    "                                        holds = False\n",
    "                if holds: print (\"FD \" + str(fd) + \" holds on this relation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if an FD holds\n",
    "Given a relation instance and a Functional Dependency, we can ask whether the FD holds on that relation instance. The algorithm is pretty simple: for every pair of tuples, we check if the two tuples have the same value for the attributes in the LHS of the FD, and if yes, we check whether they have the same value for the attributes in the RHS. E.g., to check if C --> A holds on the relation below, we note that both the tuples agree on 'C' (the LHS), but they don't agree on 'A' (the RHS). So the FD C --> A doesn't hold. \n",
    "\n",
    "The actual code for doing this is above in Relation class. Below are some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples [1, 2, 3] and [2, 2, 3] violate the FD C -> A\n",
      "FD A -> B holds on this relation\n",
      "FD A -> BC holds on this relation\n"
     ]
    }
   ],
   "source": [
    "r = Relation(['A', 'B', 'C'])\n",
    "r.add([1, 2, 3])\n",
    "r.add([2, 2, 3])\n",
    "r.checkFDHolds(FD('C', 'A'))\n",
    "r.checkFDHolds(FD('A', 'B'))\n",
    "r.checkFDHolds(FD('A', 'BC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armstrong Axioms\n",
    "Armostrong axioms are used to infer new FDs given a set of FDs. There are three basic rules as implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to construct powersets quite frequently.\n",
    "def powerset(S):\n",
    "        \"\"\"Returns the powerset of a set, except for the empty set, i.e., if S = {A, B, C}, returns {{A}, {B}, {C}, {A,B}, {B,C}, {A,C}, {A,B,C}\"\"\"\n",
    "        return list(chain.from_iterable(combinations(S, r) for r in range(1, len(S)+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following routine creates all trivial FDs using the **Reflexivity Axiom**. The reflexivity axiom states that: if A subsetof B, then B --> A is a valid FD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyreflexivity(R):\n",
    "        \"\"\"Generates all trivial dependencies, i.e., of the type X -> subset(X)\"\"\"\n",
    "        return { FD(i, j) for i in powerset(R) for j in powerset(i) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this routine does **Augmentation** given a set of functional dependencies. The augmentation axiom states that: \n",
    "if X --> Y, then XZ --> YZ, for all Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyaugmentation(F, PW, printflag):\n",
    "        \"\"\"Augmentation: if X --> Y, then XZ --> YZ\n",
    "        PW is powerset of the schema\n",
    "        \"\"\"\n",
    "        N = {FD(x.lhs.union(y), x.rhs.union(y)) for x in F for y in PW}\n",
    "        for fd in N - F:\n",
    "                if printflag: print (\"   Adding \" + str(fd) + \" by Augmenting \" + str(x) + \" using \" + \"\".join(y))\n",
    "        return F.union(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apply Transitivity to infer more axioms. Both this and the above function could be more concise if I am not printing out things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applytransitivity(F, printflag):\n",
    "        \"\"\"Transitivity: if X --> Y, and Y --> Z, then X --> Z\"\"\"\n",
    "        N = { FD(x.lhs, y.rhs)  for x in F for y in F if x.rhs == y.lhs }\n",
    "        for fd in N - F:\n",
    "                if printflag:\n",
    "                        print (\" Adding \" + str(fd) + \" using Transitivity from \" + str(x) + \" and \" + str(y))\n",
    "        return F.union(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following routine computes the Closure of a set of FDs by repeated application of the three axioms. Figure 8.7 from the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findClosure(R, F, printflag = False):\n",
    "        \"\"\"Finds closure by repeatedly applying the three Armstrong Axioms, until there is no change\"\"\"\n",
    "\n",
    "        # Start with adding all trivial dependencies generated by using Reflexivity\n",
    "        F = F.union(applyreflexivity(R))\n",
    "        powersetR = list(chain.from_iterable(combinations(list(R), r) for r in range(1, len(R)+1)))\n",
    "\n",
    "        # Repeat application of the other two rules until no change\n",
    "        done = False;\n",
    "        while done == False:\n",
    "                if printflag: print (\"Trying to find new FDs using Transitivity\")\n",
    "                F2 = applytransitivity(F, printflag)\n",
    "                if printflag: print (\"Trying to find new FDs using Augmentation\")\n",
    "                F2 = applyaugmentation(F2, powerset(R), printflag)\n",
    "                done = len(F2) == len(F)\n",
    "                F = F2\n",
    "        if printflag: print (\"Finished\")\n",
    "        return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the closure, finding keys and candidate keys is trivial. A key is any set of attribute X such that X --> R is a FD. For X to be candidate key, there shouldn't be any subset of it that is also a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findKeys(R, FClosure):\n",
    "        \"\"\"Keys are those where there is an FD with rhs = R\"\"\"\n",
    "        return { fd.lhs for fd in FClosure if len(fd.rhs) == len(list(R)) }\n",
    "\n",
    "def findCandidateKeys(R, FClosure):\n",
    "        \"\"\"Candidate keys are minimal -- go over the keys increasing order by size, and add if no subset is present\"\"\"\n",
    "        keys = findKeys(R, FClosure)\n",
    "        ckeys = set()\n",
    "        for k in sorted(keys, key=cmp_to_key(lambda x,y: cmp(len(x), len(y)))):\n",
    "                dontadd = False\n",
    "                for ck in ckeys:\n",
    "                        if(ck <= k):\n",
    "                                dontadd = True  #Found a subset already in ckeys\n",
    "                if not dontadd:\n",
    "                        ckeys.add(k)\n",
    "        return ckeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for BCNF \n",
    "The following three routines are pretty similar: one checks whether a schema is in BCNF, another lists out all the violations of BCNF, and the third one finds one of the smallest FDs that violate the BCNF condition (for decomposition purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isInBCNF(R, FClosure, keys):\n",
    "        \"\"\"Find if there is a FD alpha --> beta s.t. alpha is not a key\"\"\"\n",
    "        if keys is None: keys = Keys(R, FClosure)\n",
    "        for fd in FClosure:\n",
    "                if (not fd.isTrivial()) and (fd.lhs not in keys):\n",
    "                        return False\n",
    "        return True\n",
    "\n",
    "def listAllBCNFViolations(R, FClosure, keys):\n",
    "        \"\"\"Same as above, but finds all violations and prints them\"\"\"\n",
    "        for fd in FClosure:\n",
    "                if (not fd.isTrivial()) and (fd.lhs not in keys):\n",
    "                        print (str(fd) + \" is an FD whose LHS is not a key\")\n",
    "\n",
    "def findSmallestViolatingFD(R, FClosure, keys):\n",
    "        \"\"\"Same as above, but finds a small FD that violates\"\"\"\n",
    "        for fd in sorted(FClosure, key=cmp_to_key(lambda x,y: cmp( (len(x.lhs), len(x.rhs)), (len(y.lhs), len(y.rhs))))):\n",
    "                if (not fd.isTrivial()) and (fd.lhs not in keys):\n",
    "                        return fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCNF Decomposition\n",
    "Now we are ready to BCNF decomposition itself. First a subroutine to do a single decomposition, and then a recursive decomposition to do this until everything is in BCNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecomposeUsingFD(R, FClosure, fd):\n",
    "        \"\"\"Uses the given FD to decompose the schema -- returns the resulting schemas and their closures\n",
    "        Let the fd be X --> Y\n",
    "        Then we create two relations: R1 = X UNION Y, and R2 = X UNION (R - Y)\n",
    "        Then, for R1, we find all FDs from FClosure that apply to R1 (i.e., that only contain attributes from R1)\n",
    "        And do the same for R2\n",
    "        \"\"\"\n",
    "        R1 = fd.lhs | fd.rhs\n",
    "        R2 = set(R) - R1 | fd.lhs\n",
    "        F1Closure = { fd for fd in FClosure if (fd.lhs <= R1) and (fd.rhs <= R1) }\n",
    "        F2Closure = { fd for fd in FClosure if (fd.lhs <= R2) and (fd.rhs <= R2) }\n",
    "\n",
    "        return (R1, R2, F1Closure, F2Closure)\n",
    "\n",
    "# Do a recursive BCNF Decomposition, and print out the results\n",
    "def BCNFDecomposition(R, FClosure):\n",
    "        keys = findKeys(R, FClosure)\n",
    "        if not isInBCNF(R, FClosure, keys):\n",
    "                print (\"\".join(R) + \" is not in BCNF\")\n",
    "                fd = findSmallestViolatingFD(R, FClosure, keys)\n",
    "\n",
    "                # Decompose using that FD\n",
    "                (R1, R2, F1Closure, F2Closure) = DecomposeUsingFD(R, FClosure, fd)\n",
    "                print (\"Decomposing \" + \"\".join(R) + \" using \" + str(fd) + \" into relations \" + \"\".join(R1) + \" and \" + \"\".join(R2))\n",
    "\n",
    "                # Recurse\n",
    "                BCNFDecomposition(R1, F1Closure)\n",
    "                BCNFDecomposition(R2, F2Closure)\n",
    "        else:\n",
    "                print (\"\".join(R) + \" is in BCNF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "Here we define a relational schema and a set of FDs over it; then we find its candidate keys and print those out, and then check for BCNF and decompose it into BCNF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = \"ABCD\"\n",
    "F = {FD('A', 'B'), FD('BC', 'D'), FD('D', 'A')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA -> DBA\n",
      "DC -> DCA\n",
      "BCA -> DC\n",
      "DC -> BCA\n",
      "DC -> B\n",
      "DC -> BCD\n",
      "DC -> BDA\n",
      "BCD -> DA\n",
      "DC -> CA\n",
      "CA -> DC\n",
      "BC -> A\n",
      "BCA -> DCA\n",
      "DCA -> BCA\n",
      "DC -> DA\n",
      "BC -> BCA\n",
      "BCA -> DBCA\n",
      "CA -> D\n",
      "D -> BA\n",
      "BCA -> DBA\n",
      "BC -> BA\n",
      "BCD -> BACD\n",
      "BC -> DC\n",
      "DC -> BC\n",
      "BC -> DBCA\n",
      "BC -> DBA\n",
      "DCA -> BAD\n",
      "DC -> A\n",
      "BCD -> BA\n",
      "DCA -> BC\n",
      "BC -> DCA\n",
      "CA -> BC\n",
      "BC -> CA\n",
      "DC -> BD\n",
      "BCD -> DCA\n",
      "DCA -> BCD\n",
      "BCD -> A\n",
      "BC -> DA\n",
      "BCD -> BCA\n",
      "BCA -> DBC\n",
      "BD -> BA\n",
      "A -> BA\n",
      "CA -> DCA\n",
      "DC -> BDCA\n",
      "BC -> DB\n",
      "CA -> DBCA\n",
      "A -> B\n",
      "CA -> B\n",
      "CA -> BA\n",
      "D -> DA\n",
      "BD -> A\n",
      "BCD -> BAD\n",
      "CA -> BCA\n",
      "BCA -> DA\n",
      "DA -> BAD\n",
      "BC -> DBC\n",
      "BCA -> DB\n",
      "DCA -> BACD\n",
      "DCA -> BD\n",
      "BC -> D\n",
      "CA -> DA\n",
      "DA -> BD\n",
      "BD -> DA\n",
      "D -> B\n",
      "BCD -> CA\n",
      "CA -> DBC\n",
      "DA -> BA\n",
      "BD -> BAD\n",
      "D -> BDA\n",
      "DCA -> BA\n",
      "DCA -> B\n",
      "D -> BD\n",
      "DA -> B\n",
      "BCA -> D\n",
      "D -> A\n",
      "CA -> DB\n",
      "DC -> BA\n",
      "Keys are:\n",
      "BCA\n",
      "CA\n",
      "DC\n",
      "BDCA\n",
      "BC\n",
      "DCA\n",
      "BCD\n"
     ]
    }
   ],
   "source": [
    "Fclosure = findClosure(R, F)\n",
    "for i in Fclosure:\n",
    "        if not i.isTrivial(): print (i)\n",
    "\n",
    "keys = findKeys(R, Fclosure)\n",
    "print (\"Keys are:\")\n",
    "for i in keys:\n",
    "        print (\"\".join(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of keys -- let's find just the candidate keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Keys are:\n",
      "DC\n",
      "BC\n",
      "CA\n"
     ]
    }
   ],
   "source": [
    "candidatekeys = findCandidateKeys(R, Fclosure)\n",
    "print(\"Candidate Keys are:\")\n",
    "for i in candidatekeys:\n",
    "        print(\"\".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the schema is in BCNF\n",
      "Decomposing using B -> C into relations BC and DBA\n"
     ]
    }
   ],
   "source": [
    "print (\"Checking if the schema is in BCNF\")\n",
    "if isInBCNF(R, Fclosure, keys):\n",
    "        print (\"The schema is in BCNF\")\n",
    "\n",
    "(R1, R2, F1Closure, F2Closure) = DecomposeUsingFD(R, Fclosure, FD('B', 'C'))\n",
    "print(\"Decomposing using \" + str(FD('B', 'C')) + \" into relations \" + \"\".join(R1) + \" and \" + \"\".join(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Doing a full BCNF Decompisition -------\n",
      "ABCD is not in BCNF\n",
      "Decomposing ABCD using A -> B into relations BA and DCA\n",
      "BA is in BCNF\n",
      "DCA is not in BCNF\n",
      "Decomposing DCA using D -> A into relations DA and DC\n",
      "DA is in BCNF\n",
      "DC is in BCNF\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"-------------- Doing a full BCNF Decompisition -------\")\n",
    "BCNFDecomposition(R, Fclosure)\n",
    "print (\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "One of the examples covered in the slides. Note that: here we get a different, non-dependency-preserving decomposition into lots of 2-attribute relations. The algorithm above is not very smart -- if it had picked better FDs to do the decomposition, the final result may have been better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Keys are:\n",
      "DE\n",
      "Checking if the schema is in BCNF\n",
      "-------------- NO: Doing a full BCNF Decompisition -------\n",
      "ABCDEH is not in BCNF\n",
      "Decomposing ABCDEH using E -> H into relations EH and DECAB\n",
      "EH is in BCNF\n",
      "DECAB is not in BCNF\n",
      "Decomposing DECAB using A -> C into relations CA and DEBA\n",
      "CA is in BCNF\n",
      "DEBA is not in BCNF\n",
      "Decomposing DEBA using E -> A into relations EA and DEB\n",
      "EA is in BCNF\n",
      "DEB is not in BCNF\n",
      "Decomposing DEB using E -> B into relations BE and DE\n",
      "BE is in BCNF\n",
      "DE is in BCNF\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "R2 = \"ABCDEH\"\n",
    "F2 = {FD('A', 'BC'), FD('E', 'HA')}\n",
    "Fclosure2 = findClosure(R2, F2)\n",
    "keys = findKeys(R2, Fclosure2)\n",
    "candidatekeys = findCandidateKeys(R2, Fclosure2)\n",
    "print (\"Candidate Keys are:\")\n",
    "for i in candidatekeys:\n",
    "        print (\"\".join(i))\n",
    "print (\"Checking if the schema is in BCNF\")\n",
    "if isInBCNF(R2, Fclosure2, keys):\n",
    "        print (\"The schema is in BCNF\")\n",
    "else:\n",
    "    print (\"-------------- NO: Doing a full BCNF Decompisition -------\")\n",
    "    BCNFDecomposition(R2, Fclosure2)\n",
    "    print (\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Dependency Preserving BCNF\n",
    "Below is the smallest relation schema and FDs such that, there is no dependency-preserving BCNF decomposition. In this case, the schema is not in BCNF and needs to be split; but if we do that, then we cannot check for the FD JK --> L without doing a join. The original schema (\"JKL\") is in 3NF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JKL is not in BCNF\n",
      "Decomposing JKL using L -> K into relations KL and LJ\n",
      "KL is in BCNF\n",
      "LJ is in BCNF\n"
     ]
    }
   ],
   "source": [
    "BCNFDecomposition(\"JKL\", findClosure(\"JKL\", {FD('JK', 'L'), FD('L', 'K')}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A -> A',\n",
       " 'A -> B',\n",
       " 'A -> BA',\n",
       " 'B -> B',\n",
       " 'BA -> A',\n",
       " 'BA -> B',\n",
       " 'BA -> BA',\n",
       " 'BC -> A',\n",
       " 'BC -> B',\n",
       " 'BC -> BA',\n",
       " 'BC -> BC',\n",
       " 'BC -> BCA',\n",
       " 'BC -> C',\n",
       " 'BC -> CA',\n",
       " 'BC -> D',\n",
       " 'BC -> DA',\n",
       " 'BC -> DB',\n",
       " 'BC -> DBA',\n",
       " 'BC -> DBC',\n",
       " 'BC -> DBCA',\n",
       " 'BC -> DC',\n",
       " 'BC -> DCA',\n",
       " 'BCA -> A',\n",
       " 'BCA -> B',\n",
       " 'BCA -> BA',\n",
       " 'BCA -> BC',\n",
       " 'BCA -> BCA',\n",
       " 'BCA -> C',\n",
       " 'BCA -> CA',\n",
       " 'BCA -> D',\n",
       " 'BCA -> DA',\n",
       " 'BCA -> DB',\n",
       " 'BCA -> DBA',\n",
       " 'BCA -> DBC',\n",
       " 'BCA -> DBCA',\n",
       " 'BCA -> DC',\n",
       " 'BCA -> DCA',\n",
       " 'BCD -> A',\n",
       " 'BCD -> B',\n",
       " 'BCD -> BA',\n",
       " 'BCD -> BACD',\n",
       " 'BCD -> BAD',\n",
       " 'BCD -> BC',\n",
       " 'BCD -> BCA',\n",
       " 'BCD -> BCD',\n",
       " 'BCD -> BD',\n",
       " 'BCD -> C',\n",
       " 'BCD -> CA',\n",
       " 'BCD -> D',\n",
       " 'BCD -> DA',\n",
       " 'BCD -> DC',\n",
       " 'BCD -> DCA',\n",
       " 'BD -> A',\n",
       " 'BD -> B',\n",
       " 'BD -> BA',\n",
       " 'BD -> BAD',\n",
       " 'BD -> BD',\n",
       " 'BD -> D',\n",
       " 'BD -> DA',\n",
       " 'BDA -> A',\n",
       " 'BDA -> B',\n",
       " 'BDA -> BA',\n",
       " 'BDA -> BD',\n",
       " 'BDA -> BDA',\n",
       " 'BDA -> D',\n",
       " 'BDA -> DA',\n",
       " 'BDCA -> A',\n",
       " 'BDCA -> B',\n",
       " 'BDCA -> BA',\n",
       " 'BDCA -> BC',\n",
       " 'BDCA -> BCA',\n",
       " 'BDCA -> BCD',\n",
       " 'BDCA -> BD',\n",
       " 'BDCA -> BDA',\n",
       " 'BDCA -> BDCA',\n",
       " 'BDCA -> C',\n",
       " 'BDCA -> CA',\n",
       " 'BDCA -> D',\n",
       " 'BDCA -> DA',\n",
       " 'BDCA -> DC',\n",
       " 'BDCA -> DCA',\n",
       " 'C -> C',\n",
       " 'CA -> A',\n",
       " 'CA -> B',\n",
       " 'CA -> BA',\n",
       " 'CA -> BC',\n",
       " 'CA -> BCA',\n",
       " 'CA -> C',\n",
       " 'CA -> CA',\n",
       " 'CA -> D',\n",
       " 'CA -> DA',\n",
       " 'CA -> DB',\n",
       " 'CA -> DBA',\n",
       " 'CA -> DBC',\n",
       " 'CA -> DBCA',\n",
       " 'CA -> DC',\n",
       " 'CA -> DCA',\n",
       " 'D -> A',\n",
       " 'D -> B',\n",
       " 'D -> BA',\n",
       " 'D -> BD',\n",
       " 'D -> BDA',\n",
       " 'D -> D',\n",
       " 'D -> DA',\n",
       " 'DA -> A',\n",
       " 'DA -> B',\n",
       " 'DA -> BA',\n",
       " 'DA -> BAD',\n",
       " 'DA -> BD',\n",
       " 'DA -> D',\n",
       " 'DA -> DA',\n",
       " 'DC -> A',\n",
       " 'DC -> B',\n",
       " 'DC -> BA',\n",
       " 'DC -> BC',\n",
       " 'DC -> BCA',\n",
       " 'DC -> BCD',\n",
       " 'DC -> BD',\n",
       " 'DC -> BDA',\n",
       " 'DC -> BDCA',\n",
       " 'DC -> C',\n",
       " 'DC -> CA',\n",
       " 'DC -> D',\n",
       " 'DC -> DA',\n",
       " 'DC -> DC',\n",
       " 'DC -> DCA',\n",
       " 'DCA -> A',\n",
       " 'DCA -> B',\n",
       " 'DCA -> BA',\n",
       " 'DCA -> BACD',\n",
       " 'DCA -> BAD',\n",
       " 'DCA -> BC',\n",
       " 'DCA -> BCA',\n",
       " 'DCA -> BCD',\n",
       " 'DCA -> BD',\n",
       " 'DCA -> C',\n",
       " 'DCA -> CA',\n",
       " 'DCA -> D',\n",
       " 'DCA -> DA',\n",
       " 'DCA -> DC',\n",
       " 'DCA -> DCA'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{str(f) for f in Fclosure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCD'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A -> B', 'BC -> D', 'D -> A'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{str(f) for f in F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> B\n"
     ]
    }
   ],
   "source": [
    "print(FD('A', 'B'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
